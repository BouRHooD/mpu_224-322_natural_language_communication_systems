N-граммы в лингвистике

автоматический анализ текстов. 
  Модель N-граммы в лингвистике. Пусть задан некоторый конечный алфавит V = {wi}, где wi — символ. Языком L(V) называют множество цепочек конечной длины из символов wi. Высказыванием называют цепочку из языка. N-граммой на алфавите V называют произвольную цепочку длиной N, например последовательность из N букв русского языка одного слова, одной фразы, одного текста или, в более интересном случае, последовательность из грамматически допустимых описаний N подряд стоящих слов [1]. Грамматически корректные N-граммы могут нести разную смысловую нагрузку — во фразах «Она разинула пасть» и «Она решила пасть» слово «пасть» имеет разные значения.
  N-граммы для понимания естественного языка стали применять сравнительно недавно. Предложена вероятностная модель речи на основе теории цепей Маркова, различающая разных авторов и даже фольклор. Значение N-грамм исчерпывается их прикладной направленностью: они являются эффективным инструментом решения важной задачи — отбраковки вариантов, а их использование сводится к наложению допустимых N-грамм на имеющиеся данные [1; 2].
  Пусть C (w | w = w1, w2, ..., wn) — число вхождений строки w в генеральную совокупность ? текстов языка. Вероятность (w) появления N-граммы w находят в виде
p.
  Подобно определяют вероятность (wi) униграммы как вырожденного случая N-граммы [3]. Если вероятности появления символов в любой позиции цепочки независимы и одинаково распределены, то
n
p(w) =?p(wi) .   
i=1
  Таким образом, перестановки символов w  ?w имеют одну и ту же вероятность. Например, в языке вероятность встретить выражения «красно-коричневый» та же, что и выражение «к-рснкрчнваооиеый». Для разрешения указанного недоразумения вводят условные вероятности [3]. Тогда вероятность очередного символа строки задается в зависимости от предшествующих ему символов в виде
p(w) =p(wn | w1,w2...wn?1) p(w1,w2...wn?1),
а модель N-граммы — марковской цепью (N–1)го порядка. Задача оценивания статистических параметров N-граммы сводится к задачам по марковским цепям, а оценкой вероятности N-граммы служит частота ее встречаемости: p?(w) = f (wn | w1,w2...wn?1) =
                 = C(w1,w2 wn | L) . (1) C(w1,w2 wn?1 | L)
70	В. Ю. Гудков, Е. Ф. Гудкова

  Формула (1) для условных вероятностей триграмм использовалась в системе распознавания речи, разработанной IBM. Эксперименты показали, что в обучающей выборке отсутствовало значительное число триграмм, обнаруженное при проверке системы. Вероятность таких триграмм по (1) равна нулю, поэтому расчет p?(w) 
модифицируют [4].
  Формальные грамматики. Порождающей грамматикой G согласно [3] называется четверка G = ?N, T, P, S?, где T — алфавит терминальных, а N — нетерминальных символов; S ? N — начальный символ; P — набор правил порождения (подстановки), имеющих вид ? ? ?, где ? — строка, содержащая хотя бы один нетерминальный символ, ? — строка, включающая символы из объединенного алфавита V = N ? T. Правила подстановки также называют продукциями, а выражения в их левых частях — посылками. Говорят, что строка ? = w1?w2 выводится из ? = w1?w2, если существует правило ? ? ? (здесь w1 и w2 — строки символов из V, возможно, пустые). Запись ? ??? означает, что существует цепочка выводов, преобразующих строку ? в строку ?. Языком L(G), порождаемым грамматикой G, называют множество всех конечных строк из символов T, выводимых в грамматике G. Множество всех непустых строк из символов алфавита R обозначают R+. Очевидно, что L(G) ??T+.
  Наиболее исследован класс контекстно-свободных грамматик (КСГ), в которых правила подстановки имеют вид Ai ? ?, где A ? N, а строка ? ? V+. В частном случае КСГ — автоматные грамматики (АГ) — правила подстановки ограничивают двумя типами: A ? ?B и A ? ?, где A ? N и ? ? T.
  Определение стохастической грамматики Gs совпадает с приведенной с той лишь разницей, что все правила P = {?i ? ?j} снабжают вероятностями ij при ?pij =1. Несущей называют 
j
грамматику G, получаемую из Gs выбрасыванием вероятностей. Грамматику Gs называют согласованной, если в процессе вывода lim P(wk = {w | w ??T,  ? 1. n}) ? 1. Рассмотрим стохастическую КСГ (СКСГ) с посылками {Ai} = N. Для каждого Ai математическое ожидание Eij числа порождаемых нетерминалов (по всем продукциям A ? Aj) рассчитывают в виде
	Eij = E A(	j | Ai ) = ? p N j ikik	( ,	),
k i( )
где суммирование производится по всем k продукциям с посылкой Ai; ik — вероятность продукции A ? Ak; N(j, k) — число вхождений нетерминала Aj в правую часть продукции A ? Ak. Для СКСГ выполняется lim Et ?0 [elit??
ne 1991, Stolce 1994].
  Например, пусть S ? A1A2 с вероятностью 1, A1 ? ?A2 с вероятностью 1, A1 ? ? с вероятностью 1 — 1, A2 ? A1?A1A1  с вероятностью 2, A2 ?? с вероятностью 1 — 2. Здесь {Ai} = N = {A0 = S, A1, A2}. Тогда матрица E имеет вид
?0
E =??0
??0
1 0
3p2
1 ?
  ? p1?.
0 ??
  N-граммы и формальные грамматики. N-граммы как объект теоретического анализа недостаточно изучены. Модель N-грамм не является объяснительной и не входит ни в какую другую объяснительную модель. В качестве носителя для модели N-граммы выступает формальная грамматика. Задача заключается в том, чтобы для формальной грамматики G определить все N-граммы, допустимые в порождаемом ею языке. В вероятностной формулировке задача заключается в том, чтобы для стохастической грамматики Gs определить вероятность каждой N-граммы.
  Нормальной формой Хомского (НФХ) называется такая грамматика, в которой правила подстановки имеют вид X ? YZ, X ? t, где X, Y, Z ? N, а t ??T. К НФХ приводится любая бесконтекстная грамматика [1]. Следуя [4], через E(w|X) с подстроками  и r обозначим сумму (X ? w) и сумму по всем подстановкам в виде
	E w X(	|	) = p X( ?w) + ? p X( ?YZ)?
X YZ?
??E(?|Y)+E(?| Z) + ? p Y( ?qa p Z)	( ?br) .??
?	ab w=	?
  Алгоритм вычисления вероятностей префиксных подстрок для СКСГ приведен в [Stolce 1994]. Операция, состоящая в замене подстановки X ? YZ на X ? ZY, не выводит грамматику из класса НФХ. Известны методы, приводящие КСГ к НФХ в виде инвертированной грамматики. Применив тот же алгоритм, получим вероятности появления хвостовых подстрок для исходной грамматики.
Разновидности специальных обозначений  в современной спортивной терминологии	71

  Таким образом, N-граммы есть средство фиксации языковой реальности и модель, основанная на грамматике Хомского. Связь модельных N-грамм и формальных грамматик дает эффективный инструмент автоматического анализа печатных текстов и слитной речи человека независимо от принадлежности языка к языковой группе.
