

Подготовка данных для кластеризации событий в журналах информационной безопасности

Д.Н. Сидорова
Новосибирский государственный технический университет

Аннотация: В статье показано, что подготовка данных для использования в дальнейшем в алгоритмах играет важную роль и этому стоит уделить внимание. Рассмотрены задачи обработки исходных данных: выборка данных, очистка данных, генерация признаков, интеграция, форматирование. Исследование данных состоит в изучении следующих шагов: обобщение данных, группировка данных, исследование отношений между разными атрибутами. Приведен алгоритм действий подготовки данных в рамках событий журнала информационной безопасности для дальнейшей кластеризации.
Ключевые слова: данные, кластеризация данных, события, журнал информационной безопасности, алгоритм, Data Mining, Data Preparation, dataset, Machine Learning

     Из всех этапов анализа подготовка данных представляется наименее проблемным шагом, но на самом деле требует наибольшего количества ресурсов и времени для завершения. Во многих рассмотренных статьях [1-3] этап подготовки данных указан, как просто этап, без подробного описания, без указания сложных моментов в начале. Зачастую указано, что данные описываются в виде таблиц и все на этом, на самом деле все намного сложнее и трудозатратнее. Данные нередко собираются из различных источников, любой из которых может представлять их в своем виде либо в определенном формате. Поэтому их необходимо подготовить для процесса анализа.
     Информация, которая получена из витрины данных или корпоративного хранилища из исходных данных, зачастую имеет нечеткую структуру. Но машинное обучение не работает самостоятельно и независимо, как считают большинство пользователей. Для адекватной деятельности этого инструмента, как и любого ИТ-средства, нужны верно определенные начальные данные и инструкции. Не бывает так, что, загрузив все большие накопленные данные различных форматов в алгоритм Machine Learning,



можно получить корректные результаты на выходе. А также начальные данные часто ненадежны и изменены: они могут содержать аномальные значения (выбросы); в них могут находиться значения, которые выходят за рамки возможных значений (шумы); и отсутствовать значения (пропуски).
     Притом, нередко появляется задача подготовительной работы начальных данных. К примеру, может стоять задача установления тональности клиентских отзывов, для этого необходимо сперва разделить текст на смысловые выражения (токены), преобразовать слова («оцифровка»), перевоплотить их в числовые векторы. Из-за своеобразия местности, а именно, по причине наличия холмов или подвальных помещений, попадаются в географических данных ошибки установления координат и опечатки в адресах. В числовой последовательности наблюдаются значения, которые выходят за рамки допустимого диапазона, к примеру, цифра 11 в десятибалльной шкале оценок. Кроме того, числовые значения начальных данных могут очень колебаться по абсолютным величинам: от нескольких сотых процентов до десятков тысяч единиц. Такие погрешности изменят показатели моделирования и не разрешат получить модель машинного обучения с удовлетворительным качеством.
     Стандарты Data Mining не просто так представляют подготовку данных в отдельный этап [4]. Data Preparation – это процесс манипулирования необработанными данными в форме, которая может быть легко и точно проанализирована. Он является кропотливым итеративным, также занимает до 80 % всех затрат времени и ресурсов в жизненном цикле. В него входят задачи обработки исходных («сырых») данных, которые представлены ниже:
     1. Выбор данных – выбор признаков (функций или предикторов) и объектов с учетом их актуальности для задач Data Mining, качества и технических ограничений (размер и тип);



     2. Очистка данных – удаление опечаток, некорректных значений (например, числа в строковом параметре и т.п.), отсутствующих значений (Missing values или NA), устранение дубликатов и разных описаний одного и того же объекта, восстановление уникальности, целостность и логические отношения;
     3. Генерация признаков – получение признаков и преобразование их в векторы для модели машинного обучения, а также преобразование для повышения точности алгоритмов машинного обучения;
     4. Интеграция – объединение данных из различных источников (информационных систем, таблиц, протоколов и т. д.), в том числе, их агрегация, когда новые значения рассчитываются путем суммирования информации из множества существующих записей;
     5. Форматирование – это синтаксические изменения, не меняющие смысла данных, но требуемые инструментами моделирования, такие как сортировка в определенном порядке или удаление ненужных знаков препинания в текстовых полях, обрезка «длинных» слов, округление действительных чисел до целого, и т.п.
Подготовка данных включает такие процессы, как:
* Получение;
* Очистка;
* Нормализация;
* Превращение в оптимизированный набор данных.
     Обычно это табличная форма, подходящая для методов, которые были намечены на шаге проектировки. Перед тем, как использовать методы машинного обучения, нужно конвертировать данные в табличное представление, более распространенное в Machine Learning и Data Mining [5- 6]. Получив файл с «сырыми» данными, к примеру, в формате CSV, специалист поначалу просматривает его, чтоб осознать характер записей



(строк), также смысл, тип и спектр значений признаков (столбцов). После специалист по данным создает выборку (dataset, набор данных) – выбирает данные, связанные потенциально с проверяемой гипотезой машинного обучения. Почти все трудности могут появиться при возникновении недействительных, многосмысленных либо недостающих значений, повторении полей либо данных, несоответствующих приемлемому интервалу. Исследование данных состоит из предварительного изучения, которое необходимо для понимания типа и смысла полученной информации [7-8]. Вместе с данными, которые были собраны при определении проблемы, такая категоризация описывает, какой способ изучения данных идеальнее всего подойдет для определения модели. Изучение состоит из следующих шагов:
* Обобщение данных;
* Группировка данных;
* Исследование отношений между разными атрибутами;
* Определение моделей и тенденций;
* Построение моделей регрессионного анализа;
* Построение моделей классификации.
     Для наших данных необходимы первые три шага. Как правило, анализ данных требует обобщающих утверждений об изучаемых данных. Обобщение – это процесс уменьшения количества данных, подлежащих интерпретации, без потери важной информации.
     Кластерный анализ – метод анализа данных, используемый для поиска групп, объединенных общими атрибутами (также называется группировкой) [9]. Далее выполняется очистка данных: конвертация типов данных, агрегация признаков, заполняются отсутствующие значения, исправляются шумы и выбросы. Нормализация значений применяется к числовым переменным, чтобы привести их в один и тот же диапазон и использовать



вместе в одной модели Machine Learning. Как правило, нормализация данных означает преобразование исходных числовых значений в новые значения в диапазоне от 0 до 1 на основе начального минимума и максимума [10].
     Несмотря на работу по правильному сохранению данных для анализа, для каждой конкретной задачи всё равно могут требоваться корректировки значений. Основные манипуляции по подготовке данных проводились относительно значений Даты-Времени, а также IP-адресов источника и объекта. Результат вывода исходной таблицы с датой, приведённой в стандартный формат для работы, представлен на рис. 1.

Рис. 1 – Вывод исходной таблицы
     Далее, для приведения всех значений к типу целочисленных, значения даты и времени кодируются. IP-адреса очищаются от разделителей и так же приводятся к целочисленному типу. Результат вывода таблицы, приведённой к единому типу данных представлен на рис. 2.



Рис. 2 – Результат вывода таблицы после корректировки
     Полученные данные обладают несопоставимыми значениями. Для их использования требуется привести их к общему масштабу. Для этих целей в программе была использована нормализация на стандартное отклонение:
? = ?? ? ?
?
где ? – среднее; ? – стандартное отклонение.
     Результат вывода датасета, содержащего нормализованные значения, представлен на рис. 3.

Рис. 3 – Результат вывода с нормализованными значениями
     Полученный набор данных готов для обработки алгоритмами кластеризации.


