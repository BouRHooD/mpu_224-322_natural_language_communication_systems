Информативность N-грамм в пределах слова

Взаимная информация
Элементы теории информации интенсивно используются в
лингвистике. Понятие взаимной информации использовано в данном
сообщении для изучения информативности отдельных букв, биграмм и
триграмм в слове.
Пусть L - язык с алфавитом А, и V - список слов wi (i = 1,m)
одинаковой длины n. С каждым словом свяжем число fi - относительную
частоту встречаемости слова w1. Предположим, что 0 < f $ 1 иf = 1.
Последовательность длины s, состоящую из букв алфавита А, будем
называть n-граммой g*. В данном сообщение рассматриваются n-граммы
размеров 1, 2 и 3. N-граммы g1 также будут называться отдельными
буквами, g2 - биграммами, g3 - триграммами. Позиция n-граммы в слове
определяется позицией первой буквы входящей в п-грамму. Например, в
слове "домашний", биграмма "аш" находятся на позиции 4, и отмечается
как
Пусть W - случайная величина, значением которой является какое-
либо слово из списка V с вероятностью p(wi) = fi. Пусть Gf- другая
случайная величина, значениями которой являются n-граммы размера s,
которые могут появиться в k-й позиции в слове wi.
Количество информации, получаемой о величине W после подсчёта
величины Gf будем называть взаимной информацией этих величин. В
согласии с [Ash, 1990, раздел 1.5], количество взаимной информации
определяется по формуле
I(WiGE) = 1(GEIW) = H(GE) - H(GEIW).
(1)
Здесь H(G) - это неопределённость по поводу значения величины G
которая выражается как
H(Gp) =- p(g3)logp(gj).
где p(8j) - вероятность того, что G примет значение g* в слове wj.
Второе слагаемое в (1), H(GEIW) - это условная неопределенность
переменной Gk, порождаемая событием W. Интуитивно, это слагаемое
должно быть равно нулю, так как нет неопределенности в буквах данного
слова. В предыдущей работе [Нормантас, 2013] это утверждение
доказывается в случае отдельных букв. Посколько это доказательство
легко обобщить к случаю п-грамм, оно в данный доклад не включается.
Скомбинировав (1), (2) и приравняв H(GfIW) к 0, получим
1(WIG) =-p(e,)logp(e)).
(3)
Данная формула показывает, что количество информации об условной
вероятности события (Gf|W) равно неопределенности события,
состоящего в появлении n-граммы g* в слове w, на позиции k.
Для подсчёта p(g1) построим подмножество слов из V, состоящее из
слов,
имеющих
п-грамму
g
B
позиции
k:
V' = {w € V|w[k…k+s - 1] = g°}. Пусть частоты f', каждого слова
подмножества V' будут равны соответствующим частотам слов fj. Тогда
вероятность p(g) может быть выражена следующим образом:
V
p(g) =
(4)

Пример
Рассмотрим некоторый язык с алфавитом A = {a,b,c,d}. Табл. 1
содержит список четырехбуквенных слов с частотой их встречаемости.
Таблица 3. Пример списка слов с частотами
Слова
Относительные
частоты
аааа
0,25
baaa
0,15
сааа
0,1
bbaa
0,1
cbaa
0,3
dba
0.1
Применим формулу (4) для построения табл. 2. Например, биграмма
ba появляется в позиции 2 в трех словах: bbaa, cbaa и dbaa. Поэтому
вероятность р(G = ba) = 0,1 + 0,3 + 0,1 = 0,5.
Таблица 4. Вероятности появления биграмм в каждой позиции
Биграммы
Позиции в слове
2
aa
0,25
0,5
ba
0,15
0,5
са
bb
cb
0,1
0,1
0,3
0
(
db
0,1
0
Теперь воспользуемся формулой (3) для подсчёта информативности
биграмм в каждой позиции. В рассматриваемом примере информативность
биграмм в первой позиции подсчитывается следующим способом:
1(W|G2) = - 0,25 log 0,25 - 0,15 log 0,15 - 0,1 log 0,1 - 0,1 log 0,1 - 0,3 log 0,3 -
0,1 log 0,1 2,4 бит
Так как все слова на второй позиции имеют аа или ba с равными
вероятностями 0,5, то мы получаем ровно один бит информации:
1(W|G2) = - 0,5log 0.5 - 0,5 log 0,5 - 0 log 0 - 0log 0 - 0 log 0 - Olog 0 = 1 бит.13
B
третьей
позиции:
I(W|G;) = -1 log1 - Olog 0 - 0log0 - 0log 0 - 0log0 - 0log 0 = 0 бит.
Этот
результат следует из того факта, что все слова в нашем примере
заканчиваются на биграмму аа. Следовательно, узнав её, мы не получаем
полезной информации о слове.

3
Статистическое исследование
Для определения информативности п-грамм в словах английского,
литовского, русского, таджикского и узбекского языков и искусственного
языка эсперанто использовались те же самые частотные словари, как и
предыдущей работе [Нормантас, 2013] и [Усманов и Нормантас, 2012] с
добавлением данных узбекского языка, который прежде не изучался.
При подготовке данных к статистической обработке слова каждой
коллекции разделялись на группы, составленные из слов одинаковой
длины. Затем были подсчитаны вероятности появления каждой программы
на каждой позиции с помощью формулы (4). Далее с помощью (3) была
подсчитана взаимная информация.
Статистическое исследование было осуществлено с помощью
компьютерной программы, написанной автором
на
языке
программирования Scala. Код программы может быть выслан желающим.
4 Результаты
Результаты исследований в случае отдельных букв представлены на
рис. 1, 2 и 3 по отдельности для слов, состоящих из 5, 10, 15 букв. Они
показывают информативность букв в различных позициях в словах для 6
упомянутых языков.
На рис. 1, 2 и 3 видно, что вторая буква менее информативна по
сравнению с первой, третьей и следующими буквами до середины слова.
Например, буквы на позициях 1, 3 и 4 слов английского языка, состоящих
из 7 букв, проявляют около 4,2 бит информации о слове. Буква на позиции
2 несёт 3,8 бит. Для слов таджикского языка такого же размера эта разница
еще значительней: позиции 1, 3 и 4 доставляют 4-4,3 бит информации, а
позиция 2 - около 2,8 бит. Похожая картинка имеет место для всех языков
и длин слов.
Отметим также, что взаимная информация начинает постепенно
падать после середины слова (для слов более чем из 3 букв). Эта картина
особенно характерна для литовского, таджикского и эсперанто языков,
менее характерна для слов английского языка и почти не заметна для
русского языка. Для всех языков, кроме русского, последняя буква слова
несет наименьшую информацию в сравнении с другими позициями, за
исключением позиции 2.
На рис. 4 видно, что биграммы на позициях 3, 4 и 5 несут наибольшую
информацию в словах, состоящих из 10 букв всех шести языков. В случае
триграмм (см. рис. 5) самыми информативными являются триграммы на
позициях 3 и 4. Информативность биграмм и триграмм постепенно падает
после середины слова.
Выводы
Во всех исследованных языках наблюдаются
похожие
закономерности информативности отдельных букв: вторая буква слова
несет меньше информации по сравнению с первой и третьей буквами;
информативность букв постепенно понижается во второй половине слова.
Информативность биграмм и триграмм показывает похожие
закономерности, но в сглаженной форме.
В данной работе в первые изучалась информативность букв и n-грамм
узбекского языка. Из изученных языков, узбекский является единственным
неиндоевропейским языком (кроме эсперанто). Результаты показывают,
что картинка информативности этого языка заметно отличается только в
начале слова. Например, первые три биграммы и первые три триграммы
слов передают больше информации в сравнении с другими языками. В
случае отдельных букв, различия между узбекским и другими языками
незначительны.
Следует заметить, что хотя эсперанто - сконструированный язык, для
него имеют место те же закономерности, как и для других естественных
языков.
Необходимо проведение дальнейших исследований для объяснений
закономерностей, обнаруженных в данной статье. Автор предполагает, что
понижение информативности второй буквы может быть связано с высокой
частотой встречаемости гласных на этой позиции. Понижение
информативности между серединой и концом слова может иметь
отношение к статистическим свойствам суффиксов и окончаний.
Результаты этих исследований можно использовать, например, при
разработке или улучшении алгоритмов для поиска в текстовых данных.
Другая возможная область приложения - облегчение чтения.
