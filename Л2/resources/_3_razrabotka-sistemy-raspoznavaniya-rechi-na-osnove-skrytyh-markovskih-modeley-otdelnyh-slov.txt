РАЗРАБОТКА СИСТЕМЫ РАСПОЗНАВАНИЯ РЕЧИ НА ОСНОВЕ СКРЫТЫХ МАРКОВСКИХ МОДЕЛЕЙ ОТДЕЛЬНЫХ СЛОВ

   Распознавание голоса в компьютерных системах весьма распространено. Распо- знавание речи и, как следствие, голосовая идентификация нашли свое применение

?c Савин А. Н., Тимофеева Н. Е., Гераськин А. С., Мавлютова Ю. А., 2017

во всех сферах человеческой деятельности. Благодаря системам распознавания ре- чи обеспечивается безопасность от несанкционированного проникновения в защи- щенную зону. Такие системы содержат базу данных голосов сотрудников, имеющих доступ к защищаемой зоне, и предотвращают допуск людей, чьих голосов в ней нет [1, 2].
   В настоящее время широко разрабатываются и внедряются интеллектуальные системы управления различными объектами, которые позволяют осуществлять кон- троль за объектами в реальном времени. Управление такими системами можно осу- ществлять различными способами, одним из них является метод голосовых команд. При этом защиту объекта от несанкционированного доступа можно решить, исполь- зуя индивидуальные особенности голоса каждого человека.
   Уровень развития современной микропроцессорной техники (например, мобиль- ные устройства связи) позволяет использовать сложные вычислительные алгоритмы, основанные на цифровой потоковой обработке статистических данных в реальном времени. Поэтому разработка таких алгоритмов является весьма актуальной.
   Одним из путей решения вышеуказанных задач является использование для рас- познавания фрагментов речи математического аппарата скрытых марковских моде- лей (СММ) [3]. Данная работа посвящена разработке алгоритма и соответствующего программного модуля, осуществляющего формирование СММ для отдельных слов требуемого словаря команд системы управления объекта, на основе кодирования признаков звукового сигнала, использующего линейные предсказания.
1. СТРУКТУРА СИСТЕМЫ РАСПОЗНАВАНИЯ РЕЧИ НА ОСНОВЕ СММ
   Рассмотрим дискретную систему, имеющую конечное множество из N состоя- ний — S = {s1, . . . , sN }, в каждом из которых она может принимать одно из M значений из набора наблюдаемых параметров V = {v1, . . . , vM } — алфавита. Состоя- ние системы qt в момент времени t, принимающее одно из N значений множества S, зависит только от её состояния qt?1 в момент времени t ?1, а значение наблюдаемого параметра ot в момент времени t зависит только от состояния qt, т. е. не зависит от времени.
   Вероятности переходов между состояниями системы задаются матрицей A. Ве- роятности выпадения каждого из M значений наблюдаемого параметра системы в каждом из N состояний системы задаются набором векторов B. Вероятность по- явления некоторого начального состояния системы задаётся вектором ?. При этом последовательность состояний, в которых пребывает система Q = q1, . . . , qT , внеш- нему наблюдателю не видна, а видит он только последовательность наблюдений O = o1, . . . , oT (здесь T — длина последовательности), т. е. система ведёт себя как
«чёрный ящик». Модель такой системы получила название СММ и в компактной записи обозначается ? = (A, B, ?) [2].
   Для моделирования отдельного слова может быть выбрана лево- правая СММ (рис. 1) на основе предположения о том, что в каждый момент времени система переходит в

новое состояние [4]. Соответственно
неизвестное число скрытых состоя- ний N  в этом случае определяется

Рис. 1. Структура лево-правой СММ
Fig. 1. The structure of the left-right hidden Markov models (HMM)

длиной и количеством сегментов, на которые слово разбивается при анализе его признаков. Процесс распознавания с использованием СММ предполагает два этапа (рис. 2).

Рис. 2. Структура системы распознавания речи на основе использования СММ Fig. 2. Structure of the speech recognition system based on the use of HMM
   В режиме обучения элементы системы имеют следующее функциональное назна- чение:
речевая база содержит записи слов, повторяющихся несколько раз для обеспе-
чения адекватности получаемых СММ, которые будут доступны для распозна- вания;
выделение последовательности одинаковых слов из файла речевой базы с по- мощью предварительной обработки (подавление шума, фильтрация и т. д.); анализ признаков и определение алфавита слова V , по которому формируется последовательность наблюдений O;
обучение СММ — подбор параметров СММ, чтобы она как можно лучше опи- сывала реальную наблюдаемую последовательность O символов алфавита V анализируемого слова;
сохранение СММ в базе — словаре.
В режиме распознавания:
выделение слова из входного звукового потока с помощью предварительной
обработки;
анализ признаков распознаваемого слова и формирование соответствующей по- следовательности наблюдений O;
распознавание слова с использованием базы СММ и генерация кода распозна- ваемого слова.
Таким образом, для реализации данной структуры необходимо всего 4 модуля:
модуль выделения слов из звукового потока, модуль анализа признаков слова, модуль обучения СММ с базой моделей, модуль распознавания слов.
2. АЛГОРИТМ ВЫДЕЛЕНИЯ ОТДЕЛЬНЫХ СЛОВ ИЗ ЕДИНОГО ЗВУКОВОГО ФАЙЛА
   В режиме обучения файл должен содержать несколько раз произнесенное одним диктором требуемое слово. Это необходимо для получения достоверной последо- вательности наблюдений O, соответствующей данному слову. На рис. 3 приведена блок-схема алгоритма предварительной обработки звукового файла, основанного на



Рис. 3. Блок-схема алгоритма выделения отдельных повторяющихся слов из звукового файла
Fig. 3. A flowchart of an algorithm for selecting separate repetitive words from a sound file

вычислении огибающей и выделении на ее основе участков файла соответствующих повторяющимся словам.
   При этом на выходе формируется массив отрезков звукового файла одинаковой длины, соответствующих повторяемому слову, что позволяет использовать усреднен- ные входные данные при обучении СММ слова, делая её тем самым более адекват- ной.
   Алгоритм выделения отдельных слов из звукового потока встроен в модуль построения СММ слов, реализованный в среде графического программирования LabVIEW компании National Instruments [5]. На рис. 4 показан процесс выделе- ния команды из звукового файла, содержащего десять раз повторяющееся слово
«Вперёд».

Рис. 4. Выделение повторяющихся слов из звукового файла Fig. 4. Selecting duplicate words from a sound file

   На первом графике рис. 4 чёрным изображен исходный сигнал, серым — от- фильтрованный, с измененной частотой дискретизации и нормированный. Из запи- си убираются первые 0.1 с, соответствующие переходным процессам при включении микрофона и предварительной фильтрации.
   Выделение слова осуществляется путем анализа огибающей сигнала. Индексы, в которых огибающая начинает превышать заданный в начале уровень шума, соот- ветствуют началу команды. Индексы, в которых огибающая становится ниже уровня шума, — концу команды. Паузы внутри команды отсеиваются с помощью задан- ной заранее минимальной длительности команд. Таким же образом отсеиваются и лишние шумы.
   Элементы управления модуля (граничные частоты среза входного полосового фильтра, частота дискретизации сигнала для анализа признаков, параметры НЧ

фильтра огибающей, уровень шума огибающей, минимальная длительность команды) позволяют подбирать требуемые параметры на этапе выделения команд для обеспе- чения построения адекватных СММ слов.
3. АЛГОРИТМ АНАЛИЗА ПРИЗНАКОВ СЛОВ
   Для системы распознавания речи каждому слову необходимо сопоставить набор признаков. Этот процесс в [4] предложено осуществлять на основе анализа периодич- ности спектра фрагментов звукового сигнала (кепстральный анализ), предварительно обработанного с помощью алгоритмов линейного предсказания. Такой процесс назы- вается кодированием на основе линейного предсказания (КЛП). Алгоритм анализа признаков на основе КЛП, используемый при распознавании отдельных слов, приве- ден на рис. 5, 6.

  Рис. 5. Блок-схема процедуры алгоритма Левинсона вычисления КЛП-коэффициентов Fig. 5. Block diagram of the procedure of Levinson’s algorithm for calculating linear prediction
coding (LPC) coefficients




Рис. 6. Блок-схема алгоритма анализа признаков слова на основе КЛП Fig. 6. Flowchart of word analysis algorithm based on LPC

   Достоинством спектральной обработки звуковых сигналов является то, что при переходе из временной области в частотную представление информации становится

более наглядным, компактным. Причем, чем более «простым» является сигнал во временной области, тем в большей степени происходит сжатие информации.
   Выявление периодичности в спектре (кепстральный анализ) позволяет более до- стоверно и точно охарактеризовать особенности произношения дикторов. При этом спектральная информация представляется еще более компактно. Каждый гармони- ческий ряд исходного спектра представляется в идеале всего одной составляющей в кепстре [4].
   Использование линейного предсказания, основанного на автокорреляционной фильтрации, должно улучшать отношение сигнал – шум исходного сигнала и убирать из него случайные артефакты. Вычисление коэффициентов линейного предсказания осуществляется с помощью алгоритма Левинсона (см. рис. 5) [6].
   В процессе анализа признаков слова каждый участок, выделенный ранее из файла и соответствующий повторяющемуся слову, разбивается на небольшие перекрываю- щиеся отрезки – сегменты и затем обрабатывается согласно алгоритму, приведенному на рис. 5, 6. Как видно (рис. 7, а), в результате предискажения сигнала происходит выравнивание спектра, что обеспечивает равноценность спектральных компонент при анализе признаков.
   Оконное взвешивание (рис. 7, б) уменьшает сигнал на концах сегментов и уве- личивает в центре, минимизируя нежелательные концевые эффекты.
   Линейное предсказание (рис. 7, в) на основе алгоритма Левинсона (см. рис. 5) убирает сглаживает выбросы и случайные артефакты в анализируемом сигнале.

а / a	б / b

в / с
Рис. 7. Спектр исходного (–) и предискаженного (–) сигналов (а), исходный (–) и взвешенный (–) сегменты сигнала (б), исходный взвешенный (–) и предсказанный (–) сегменты сигнала (в)
Fig. 7. The spectrum of the initial (–) and pre-faded (–) signals (a), the initial (–) and weighted (–) signal segments (b), the initial weighted (–) and predicted (–) signal segments (c)

   На выходе алгоритма формируется необходимая для распознавания слова матри- ца, строки которой образуются конкатенацией взвешенного кепстрального и соот- ветствующего взвешенного дельта-кепстрального векторов сегментов. Каждая такая строка является набором признаков сегмента — вектором наблюдений и соответству- ет одному символу из алфавита V СММ слова в последовательности наблюдений O. Количество строк определяет число состояний N , в которых находилась лево-правая СММ слова.
   Настройка параметров КЛП (число отсчётов в сегменте NA, число отсчётов в смещении сегментов MA, порядок КЛП-анализа p, число кепстральных коэффици- ентов U ) осуществляется посредством соответсвующих элементов (см. рис. 5).
4. ПОСТРОЕНИЕ СММ СЛОВА
   В процессе построения СММ слова для повышения её адекватности необходимо использовать матрицу векторов наблюдений, полученную статистическим усреднени- ем матриц векторов наблюдений повторяющихся слов. При этом усредняются векто- ра наблюдений, соответствующие одним и тем же моментам времени повторяющихся слов.
   Оценка достоверности выборочных средних значений признаков сегментов (эле- ментов векторов наблюдений) повторяющихся слов проводится с помощью довери- тельных интервалов, вычисляемых при уровне статистической значимости ? = 0, 05. Сравнение степени разброса, т. е. оценка однородности выборочных дисперсий значений элементов векторов наблюдений, вычисленных по результатам анализа при- знаков повторяющихся слов, осуществляется с использованием критерия Кохрена [7] Обеспечение статистически значимых выборочных средних значений элементов векторов наблюдений и однородности их дисперсий, т. е. получение достоверной по- следовательности наблюдений для анализируемого слова, достигается подбором па-
раметров обработки входного сигнала и параметров КЛП (см. п. 2, 3).
   Оценку расстояния между символами алфавита V слова — усреднёнными век- торами наблюдений — было предложено делать с помощью евклидовой нормы. При этом для обеспечения равнозначности признаков при вычислении расстояния про- водилась их нормировка. В качестве нормирующего для каждого элемента вектора наблюдений использовался диапазон его изменения в матрице, расширенный с учё- том доверительного интервала.
   Формирование алфавита СММ слова осуществляется удалением повторяющихся строк из нормированной матрицы средних значений наблюдений, если такие имеют- ся. При этом сравнивается расстояние между текущей строкой и остальными. Если оно меньше некоторой заданной величины, то строка с большим индексом удаля- ется, так как считаем, что эти строки соответствуют одному и тому же символу. Соответственно число строк получившейся прореженной матрицы определяет коли- чество символов M алфавита V , индексы строк являются значениями алфавита, а сами строки — признаками символов.
   Последовательность наблюдений слова определяется сравнением строк матрицы алфавита V (прореженной) с исходной нормированной матрицей средних значений наблюдений. Если расстояние между строками меньше некоторой заданной величи- ны, использованной при построении алфавита, то индекс строки матрицы алфави- та V записывается в последовательность наблюдений O. Длина последовательности наблюдений T равна числу строк исходной матрицы, а число состояний N равно T в случае лево-правой СММ слова.

   На рис. 8 приведены результаты экспериментов по определению числа состоя- ний N для слов «Вперёд» и «Стоп». На вход модуля построения СММ для каждого из этих слов подавалось тридцать звуковых файлов, содержащих по пятнадцать повторений, произнесённых одним диктором. Во всех случаях число состояний N совпадало с количеством символов M алфавита V , что соответствует предположе- нию о лево-правой структуре СММ (см. рис. 1) для этих слов из-за отсутствия в них повторяющихся звуков.

а / a	б / b
Рис. 8. Количество полученных в экспериментах состояний для слов «Вперёд» (а) и «Стоп» (б)
Fig. 8. The number of states obtained in the experiments for the words „Forward“ (a) and „Stop“ (b)
   Как видно из рис. 8, закон распределения отклонений числа состояний N от средних значений близок к нормальному. Соответственно для слова «Вперёд» сред- нее значение N составило 18 2.6% при 95% -й доверительной вероятности, а для слова «Стоп» — 6  5.7%.
   Следовательно, данные, полученные с помощью предложенного алгоритма пред- варительной обработки звукового файла в совокупности с КЛП-анализом, являются достаточно надёжными и их можно использовать для построения СММ слова.
   Процесс построения начинается генерированием по известному числу состояний N и количеству символов M алфавита V исходной СММ ? = (A, B, ?), имеющей случайные параметры. При этом матрица вероятностей переходов между состояни- ями A, матрица вероятностей каждого наблюдения в каждом состоянии B, а также вектор вероятностей начального состояния ? должны удовлетворять стохастическим ограничениям [3].
   Далее необходимо так подобрать параметры исходной СММ, чтобы вероят- ность соответствия последовательности наблюдений, сгенерированной этой СММ ?? = (A?, B?, ??) и полученной ранее последовательности наблюдений O = o1, . . . , oT слова, была максимально возможной. То есть исходную СММ ? = (A, B, ?), име- ющую вероятность p(O|?) генерирования заданной последовательности наблюде- ния O = o1, . . . , oT слова, надо обучить по этой последовательности наблюде- ния O = o1, . . . , oT , чтобы вероятность p(O ??) генерирования последовательности
O = o1, . . . , oT , обученной СММ ?? = (A?, B?, ??), была максимально возможной.
Одним из вариантов обучения СММ ? = (A, B, ?) по заданной последовательно-
сти наблюдений O = o1, . . . , oT является применение алгоритма Баума – Велша [3].

   Алгоритм позволяет уточнять параметры исходной СММ ? = (A, B, ?) таким образом, чтобы у уточнённой СММ ?? = (A?, B?, ??) вероятность p(O ??) увеличи- валась. Итеративное применении алгоритма до схождения в одной точке позволяет максимизировать p(O|??), т. е. настроить СММ ?? = (A?, B?, ??) на заданную после- довательность наблюдений O = o1, . . . , oT слова. На рис. 9 приведены зависимости изменений вероятности p(O ??) и её приращения ?p(O ??) на каждом итерационном шаге при настройке методом Баума – Велша СММ на слово «Стоп». Эти зависимости имеют характерный для метода Баума – Велша вид.
   В начале обучения значения вероятности p(O ??) имеют, как правило, величи- ны меньшие или сравнимые с используемой для оценки сходимости положительной величиной ? (см. рис. 9, а), но разность значений p(O|??) на каждом шаге увеличи- вается, т. е. приращение ?p(O|??) > 0 растет (см. рис. 9, б).
   При завершении обучения значения вероятности p(O ??), как правило, сходятся к некоторой величине, при этом приращение ?p(O ??) > 0, но оно начинает умень- шаться и стремиться к 0.


а / a	б / b
Рис. 9. Изменения вероятности СММ p(O|??): а — и её приращения ?p(O|??); б — при обучении методом Баума – Велша
Fig. 9. Changes in the probability of the HMM p(O|??): a — and its increment ?p(O|??);
b — when learning by the Baum – Welsh method

   Следовательно, для корректной оценки сходимости итерационного процесса обу- чения необходимо контролировать не только величину приращения ?p(O ??), но и знак его изменения, т. е. для завершения обучения должно выполняться условие
?p(O|??) ? ? при уменьшении ?p(O|??).
   В разработанном модуле построения СММ для оценки сходимости процесса обу- чения использовано значение ? = 1.1 ? 10?19, соответствующее машинной точности. Недостатком алгоритма Баума – Велша при обучении СММ является поиск ло- кального максимума p(O ??), а не глобального. Поэтому для достижения хорошего результата требуется, как правило, несколько запусков при различных начальных
условиях.
   Таким образом, используя последовательности наблюдений и алфавит моделиру- емых слов, получаемые на первых этапах обработки, с помощью алгоритма Баума – Велша можно строить соответствующие адекватные СММ для систем распознавания речи.

ЗАКЛЮЧЕНИЕ
   Разработанный программный модуль позволяет эффективно подготавливать необ- ходимые исходные данные на основе кодирования признаков звукового сигнала, ис- пользующего линейные предсказания, строить СММ отдельных слов и проводить их обучение с помощью алгоритма Баума – Велша. Построенные СММ слов предполага- ется использовать в интеллектуальных системах управления различными объектами.


















