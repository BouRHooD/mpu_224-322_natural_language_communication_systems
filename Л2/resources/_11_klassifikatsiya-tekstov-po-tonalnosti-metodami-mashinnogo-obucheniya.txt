
КЛАССИФИКАЦИЯ ТЕКСТОВ ПО ТОНАЛЬНОСТИ МЕТОДАМИ МАШИННОГО ОБУЧЕНИЯ
    В современном мире задача классификации текстов получила боль- шое распространение вследствие увеличения объема текстовой инфор- мации в мировом информационном пространстве. В связи с этим возни- кает потребность в системах обработки текстовой информации, её хра- нения и анализа.
    Предположим, имеется некоторый текст, который может представ- лять собой сообщение, отзыв или комментарий. Задачей является опре- делить, какую эмоцию несет в себе этот текст: симпатия, разочарование, восторг, недовольство, сомнение и т. п. В общем случае эмоции можно классифицировать на позитивные и негативные (положительные и отри- цательные), поэтому в работе рассматривается именно задача бинарной классификации.
    В статье кратко рассмотрены существующие методы классификации текстов   по   тональности,   разработана   функционирующая    модель для классификации текстов по тональности, а также проведены экспери- ментальные исследования на тестовых данных.
1. Постановка задачи и обзор методов классификации текстов
    Анализ тональности текста является подзадачей обработки есте- ственного языка (Natural Language Processing, NLP), цель которой — классификация текста в соответствии с эмоциональной окраской, кото- рую он в себе несет [1].
    Существуют две основные группы подходов к анализу тональности текстов: подходы на основе правил (лингвистические) и подходы на ос- нове машинного обучения. Подходы на основе машинного обучения (с учителем) более универсальны и не требуют создания словарей и пра- вил для конкретной предметной области, поэтому в данной статье рас- сматриваются именно такие методы.
    Задача классификации текстов по тональности формализуется сле- дующим образом: необходимо построить модель для классификации F, которая после обучения на выборке D определяет текст Ti к одному из классов множества y — то есть к отрицательному или положительному классу текстов:

F ?D,Ti ? ??y1, y2?.

(1)


    Поставленная задача классификации может решаться с помощью различных методов машинного обучения, а также с помощью нейронных

сетей [2]. В последние годы все чаще используются методы глубокого обучения (Deep Learning), к которым относятся нейронные сети. Такие методы могут значительно превосходить классические методы в задаче анализа тональности текстов [3]. Среди различных видов нейронных се- тей класс рекуррентных нейросетей зачастую превосходит другие классы в рассматриваемой задаче [1].
    Рекуррентные сети имеют обратные связи, и для вычисления теку- щего состояния они используют предыдущие состояния [4]. Это важно для анализа тональности текста, ведь при определении эмоциональной окраски текста важно анализировать текст именно как последователь- ность. Рекуррентные нейронные сети имеют весомый недостаток: при каждой итерации информация в памяти смешивается с новой информа- цией, а после нескольких итераций полностью перезаписывается. Такая проблема называется проблемой исчезающего градиента (vanishing gradient problem) [5].
    Архитектура рекуррентной нейронной сети, которая позволяет уменьшить проблему исчезающего градиента — «Долгая краткосрочная память» (от англ. Long Short Term Memory — LSTM) [6]. LSTM-сети не- редко применяются в задаче классификации текстов и, в частности, клас- сификации текстов по тональности. Такая архитектура зачастую показы- вает достаточно высокие результаты по сравнению как с другими мето- дами машинного обучения, так и с другими архитектурами нейронных сетей [7, 8], поэтому основу созданной модели составляет LSTM-сеть.
2. Сеть LSTM — «Долгая краткосрочная память»
    В сетях LSTM элементом сети является набор слоёв, взаимодей- ствующих друг с другом по определённым правилам. Подобные наборы называются ячейками. Структура LSTM сети, развернутой во времени, представлена на рисунке 1.



Рис. 1. Сеть LSTM, развернутая во времени

    На вход сети в разные моменты времени поступают элементы по- следовательности xt-1, xt, xt+1, и в каждый момент времени сеть выдает значения ht-1, ht, ht+1. Такая сеть передает два значения на вход своей ко- пии в следующий момент времени. Работа ячейки описывается набором формул (2):

ft ? ? (Wf xt ?Uf ht ?1);

it ? ? (Wi xt ?Uiht ?1 );
Сt ? tanh(Wc xt ?Ucht ?1 );
(2)
Ct ? ft *Ct ?1 ? it *Ct ;

ot ? ? (W0 xt ?U0ht ?1 );

ht ? ot * tanh(Ct );

где ft — выходной вектор вентиля забвения, it — выходной вектор вход-

ного вентиля, Сt

— вектор новых значений-кандидатов, которые можно

добавить в состояние ячейки, Ct — новое состояние ячейки, ot — вектор выходного вентиля. Более подробно работа данной архитектуры описана в книге [9].
3. Создание и обучение нейросети
3.1. Используемые средства и наборы данных
    Для решения поставленной задачи использовался язык программи- рования Python, а также библиотеки TensorFlow и Keras.
    В качестве наборов данных для обучения и тестирования были ис- пользованы YELP [10] и Large Movie Review Dataset (IMDB) [11]. Набор данных Yelp reviews Polarity содержит отзывы о различных услугах, сер- висах и местах на английском языке. Набор IMDB содержит рецензии на различные фильмы на английском языке.
    Говоря об анализе эмоциональной окраски текстов, важно учиты- вать, что тексты в интернете могут иметь разную специфику: например, нейронная сеть, обученная на наборе данных с рецензиями на книги, мо- жет плохо справляться с определением тональности комментариев в со- циальной сети. Это связано с тем, что такие тексты имеют ряд различий: у них может значительно отличаться длина (количество слов), лексика (более формальная, либо же более свободная с использованием сленга и аббревиатур), и т. д. Поэтому с целью создания наиболее универсальной модели нейронной сети для ее обучения было принято решение исполь- зовать тренировочный набор, составленный из отзывов набора YELP и набора IMDB в совокупности. После слияния тренировочных наборов было получено 604000 отзывов для обучения нейронной сети, структура полученного набора представлена на рисунке 2.



Рис. 2. Структура тренировочного набора

3.2. Предварительная обработка данных
    К этапу предобработки данных на естественном языке относятся: очистка данных (удаление из исходного текста особых знаков, символов, пунктуации), предварительная обработка данных (например, перевод всех символов текста в нижний регистр), а также удаление стоп-слов (это часто используемые слова, которые не влияют на смысл текста, такие как артикли, предлоги, союзы, частицы, местоимения).
    Однако для задачи анализа тональности текста нельзя удалять все стоп-слова, так как это может отразиться на эмоциональной окраске от- зыва. Например, текст “The movie was not good at all” (фильм был не со- всем хорош) после удаления стоп-слов превратится в “movie good” (фильм хорош). Как можно заметить, тональность текста при удалении стоп-слов изменилась на противоположную. Кроме того, слова, усили- вающие тональность, также стоит оставить в текстах. Таким образом, из списка стоп-слов были удалены слова “no”, “not”, обозначающие отри- цание, и “very”, усиливающее тональность последующего слова.
    Воспользуемся методом Word2Vec для получения векторных пред- ставлений слов и обучим модель на корпусе отзывов тренировочного набора. Word2Vec — одна из наиболее эффективных и широко исполь- зуемых моделей для формирования векторных представлений слов. Ме- тод основывается на том, что слова, которые похожи по значению, долж- ны иметь схожие значения векторов [12]. В данной работе учитываются
6 соседних слов из контекста, в модель сохраняются слова, которые встречаются более 1 раза.
    Далее воспользуемся классом Tokenizer и обучим его на отзывах. В процессе обучения строится словарь соответствия каждого слова и его числового представления. Токенизация производится, опираясь на то, как часто каждое слово встречается в тексте. Затем преобразуем текст в число- вое представление (последовательность) на обученном токенайзере.

    Ограничим максимальную длину отзыва средним количеством слов в рассматриваемых текстах — числом 100. Если в отзыве больше задан- ного количества слов, он обрезается, если же меньше — он дополняется нулями в начале числовой последовательности до заданного размера.
3.3. Создание и обучение модели
    Для создания нейронной сети был использован последовательный тип модели Sequential, где можно последовательно добавлять слои. Пер- вый слой — Embedding («слой встраивания») который содержит матрицу встраивания, полученную после обучения модели Word2Vec. Параметр trainable равен False, так как эта модель уже обучена. Длина последова- тельностей, подаваемых на вход, равна 100, как и длина ограниченных ранее отзывов. Второй слой — LSTM со 128 ячейками. Выходной слой выдает 1 нейрон, функция активации — сигмоидальная. Схема модели приведена на рисунке 3.

Рис. 3. Схема модели нейронной сети
    Для компиляции модели в качестве оптимизатора используем Adam, в качестве функции потери применялась бинарная кросс-энтропия, а в качестве метрик для оценки модели — accuracy (доля правильных от- ветов), precision (точность) и recall (полнота). Подробно метрики рас- смотрены в работе [13].
    Для того, чтобы обойти проблему переобучения, можно использо- вать callback (обратный вызов): таким образом, модель будет сохранять- ся на каждой эпохе обучения, а лучшая копия (по параметру точности на проверочном наборе данных) будет сохранена в файл.
    При обучении нейросети зададим следующие параметры: эпох — 12, размер минимальной выборки — 128, а также для проверки на прове- рочном наборе данных будет использоваться 10 % набора.
    График долей правильных ответов классификатора приведен на ри- сунке 4.



Рис. 4. График долей правильных ответов классификатора на обучающем и проверочном наборах
    Наибольшая доля правильных ответов на проверочном наборе дан- ных была достигнута на эпохе 9 — это 0.94463 (или 94,463 %). Таблица всех используемых метрик на обучающей и проверочной выборке для лучшей модели сети приведена ниже (табл. 1).
Таблица 1
Значения метрик качества для обучающей и проверочной выборки тренировочного набора

Тип выборки
Доля верных ответов
Точность
Полнота
Обучающая выборка
0.9531
0.9527
0.9535
Проверочная выборка
0.9446
0.9437
0.9453
4. Оценка полученных результатов и варианты внедрения
4.1. Оценка работы модели на тестовых наборах
    Для тестирования используем тестовые выборки из датасетов YELP и IMDB, на которых обучалась модель. В таблице 2 представлены мет- рики для обоих наборов.
Таблица 2
Метрики качества работы нейросети на тестовых наборах

Тестовый набор
Доля верных ответов
Точность
Полнота
Тест. набор YELP
0,9498
0.9572
0.9418
Тест. набор IMDB
0,8920
0.8932
0,8892
    Таким образом, были получены достаточно высокие доли верных ответов на обоих тестовых наборах — почти 95 % на YELP и чуть боль- ше 89 % на IMDB. Точность выше на первом наборе, так как он намного больше набора с рецензиями, и для обучения нейронной сети доминиру- ющую часть обучающего набора составляли именно отзывы из YELP. Соответственно, полученная модель с большой точностью классифици- рует подобные отзывы о товарах, услугах и сервисах, однако с рецензия- ми на фильмы она также справляется на достаточно высоком уровне.

    Для того, чтобы сравнить эффективность работы различных методов машинного обучения с полученной моделью нейронной сети, воспользу- емся библиотекой Sklearn. Применим наивный байесовский классифика- тор, логистическую регрессию и стохастический градиентный спуск к тем же наборам данных, с которыми работали ранее: для обучения ис- пользуем объединенный корпус из отзывов наборов YELP и рецензий IMDB, а для тестирования — тестовые наборы этих датасетов. Также проведем процесс предварительной обработки текстов с обоими набора- ми, затем применим векторизацию. В таблице 3 представлено сравнение результатов разработанной модели с другими методами машинного обу- чения.
Таблица 3
Сравнение методов машинного обучения в задаче классификации текста по тональности
Метод машинного обучения
Доля верных ответов

YELP
IMDB
Наивный байесовский классификатор
0.8119
0.8003
Логистическая регрессия
0.9279
0.8688
Стохастический градиентный спуск
0.9293
0.8793
Разработанная модель (Word2Vec + LSTM)
0.9498
0.8920
    Как можно заметить, полученная модель нейронной сети показывает наибольшую точность по сравнению с другими методами на обоих те- стовых наборах данных.
4.2. Пример практического использования модели
    Полученная модель достаточно универсальна и может применяться в различных областях, где тональность текстов имеет значение. Чтобы проиллюстрировать практическое применение, был выбран анализ ком- ментариев под видео на сайте YouTube. Не так давно видеохостинг от- ключил демонстрацию количества отрицательных отметок к видео (диз- лайков), поэтому нельзя понять мнение пользователей о видео по соот- ношению отметок (лайков/дизлайков), как это было ранее. Для этого можно воспользоваться анализом тональности отзывов и понять соотно- шение положительных и отрицательных мнений.
    Сначала необходимо объединить комментарии в набор данных, за- тем применить к нему функцию предварительной обработки текста и удалить пустые строки. Далее нужно загрузить и применить предобучен- ный токенайзер, а также модель нейронной сети. Можно проиллюстри- ровать полученные результаты с помощью круговой диаграммы (рис. 5).



Рис. 5. Пример диаграммы положительных и отрицательных отзывов о видео

    Таким образом, применяя полученную в этой работе модель, можно вывести соотношение положительных и отрицательных мнений о видео, представив их наглядно в виде диаграмм. Нельзя исключать тот факт, что какой-то процент отзывов скорее бы относился к «нейтральным» при рассмотрении трех классов текстов (положительные, отрицательные и нейтральные), однако рассмотренная бинарная классификация предо- ставляет более «грубую» статистику, что также, безусловно, важно для различных целей.
Заключение
    В работе были рассмотрены различные методы машинного обуче- ния для задачи классификации текстов. Кроме того, были изучены научные статьи на тему нейронных сетей в задачах анализа данных на естественном языке. Была создана нейронная сеть на языке Python с использованием библиотек TensorFlow и Keras. Нейросеть была обу- чена на наборах данных YELP и IMDB, которые включают отзывы на различные услуги и места, а также рецензии на фильмы.
    Полученная модель нейросети показала высокий результат в зада- че классификации текстов по тональности: доля верных ответов на те- стовых наборах данных составила почти 95 % на наборе YELP и чуть больше 89 % на наборе IMDB. Также был проиллюстрирован пример практического использования результатов проведенного исследования. Таким образом, полученная модель нейронной сети для классифи- кации текстов по тональности имеет высокую точность и может при- меняться для различных прикладных задач, таких, как, например, ана- лиз мнений о различных товарах и услугах или оценка реакции людей
разного рода события или изменения.




